# Generation
from langchain.prompts import ChatPromptTemplate
from langchain_google_genai import GoogleGenerativeAI
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser


llm = GoogleGenerativeAI(model="models/gemini-2.5-pro")

prompt = ChatPromptTemplate.from_template(
    """Answer the user's question based on the context provided.
    Context: {context}
    Question: {question}
    Answer:"""
)

# Post-processing
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

# Chain
rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# Question
rag_chain.invoke("অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?")
